<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AWS Tutorials on My Journey</title>
    <link>https://omar2cloud.github.io/aws/</link>
    <description>Recent content in AWS Tutorials on My Journey</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://omar2cloud.github.io/aws/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Install Unified CloudWatch Agent</title>
      <link>https://omar2cloud.github.io/aws/cloudwatch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://omar2cloud.github.io/aws/cloudwatch/</guid>
      <description>Install Unified CloudWatch Agent: The unified CloudWatch agent. It enables you to collect both logs and advanced metrics with one agent. It offers support across operating systems, including servers running Windows Server. This agent also provides better performance. The older CloudWatch Logs agent, which supports the collection of logs from only servers running Linux. AWS strongly recommends migrating to the unified CloudWatch agent.
The unified CloudWatch agent enables you to do the following: 1- Collect more system-level metrics from Amazon EC2 instances across operating systems.</description>
    </item>
    
    <item>
      <title>install Mattermost and MySQL on EC2</title>
      <link>https://omar2cloud.github.io/aws/mattermost/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://omar2cloud.github.io/aws/mattermost/</guid>
      <description>Mattermost Mattermost is an open-source, self-hostable online chat service with file sharing, search, and integrations. It is designed as an internal chat for organizations and companies, and mostly markets itself as an open-source alternative to Slack and Microsoft Teams. For information about Mattermost.
As part of this tutorial, we will install and configure MySQL on Ubuntu 20.04 LTS EC2 instance. The intension is implement two different subnets, Public and Private subnets.</description>
    </item>
    
    <item>
      <title>AWS Lambda Custom Layers and a Lambda Function in Python</title>
      <link>https://omar2cloud.github.io/aws/lambda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://omar2cloud.github.io/aws/lambda/</guid>
      <description>What is AWS Lambda? AWS Lambda is a serverless compute service, which allow the user to run codes without provisioning or managing servers. With Lambda, the user does not manage runtimes nor admin the server. Utilizing Lambda is as simple as uploading a code in a ZIP file or a container image, and Lambda automatically allocates compute execution power and runs the code based on the incoming request or event. Lambda functions can be written in many flavors such as, Node.</description>
    </item>
    
    <item>
      <title>Application Load Balancer with Lambda Backend</title>
      <link>https://omar2cloud.github.io/aws/lambda_web/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://omar2cloud.github.io/aws/lambda_web/</guid>
      <description>Application Load Balancer An Application Load Balancer has the ability to send traffic to a specific target group (TG) based on path. The default path is to send all the traffic to a given Target Group.. Usually a TG comprises of infrastructure components either on the cloud (EC2 instances) or from on-prem data-center (via IP).
However, there is an exciting feature by which the target group can contain a lambda function as the backend.</description>
    </item>
    
    <item>
      <title>Invoice Processing Application</title>
      <link>https://omar2cloud.github.io/aws/prj2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://omar2cloud.github.io/aws/prj2/</guid>
      <description>Invoice Processing Application The Invoice Processing Application is to parse the content of the uploaded text format invoices to S3 bucket using a Python custom code running on a Ubuntu EC2 to convert them into CSV records. Once a record is processed, it will be saved in DynamoDB for retention and the converted CSV record is saved in S3 destination bucket. AWS Athena is to query the CSV records to aggregate expenses grouped by date.</description>
    </item>
    
    <item>
      <title>Docker Image on ECS Fargate</title>
      <link>https://omar2cloud.github.io/aws/prj3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://omar2cloud.github.io/aws/prj3/</guid>
      <description>A Sample Web Application Containerized as a Docker image Deployed on AWS ECS Fargate In this tutorial, we will package and containerize a sample web application as a Docker image running on Apache Tomcat having JRE-8 as a runtime. Then, we will push this new Docker image to our public repository at Dockerhub. The web application, which is packaged into a Docker image will be deployed on AWS ECS Fargate cluster.</description>
    </item>
    
    <item>
      <title>Image Analysis with AWS Rekognition</title>
      <link>https://omar2cloud.github.io/aws/rekognition/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://omar2cloud.github.io/aws/rekognition/</guid>
      <description>AWS Rekognition Amazon Rekognition is part of AWS cognitive services, which requires no machine learning expertise to use. It&amp;rsquo;s a simple way to analysis images and videos for any application using proven record of high scalability and deep learning technology. Rekognition technology is utilized to identify and detect objects, shapes, people, texts, and activities in media contents. For more about Amazon Rekognition.
In this tutorial, we will explore the important aspect of AWS Rekognition and practically detect people and text on sample picture and video utilizing boto3 - AWS Python library.</description>
    </item>
    
    <item>
      <title>Create a Simple AWS CodePipeline from CodeCommit and Elastic Beanstalk</title>
      <link>https://omar2cloud.github.io/aws/_codecommit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://omar2cloud.github.io/aws/_codecommit/</guid>
      <description>AWS CodeCommit, Elastic Beanstalk and CodePipeline AWS CodeCommit is a fully-managed source control service that hosts secure Git-based repositories. It makes it easy for teams to collaborate on code in a secure and highly scalable ecosystem. CodeCommit eliminates the need to operate your own source control system or worry about scaling its infrastructure. You can use CodeCommit to securely store anything from source code to binaries, and it works seamlessly with your existing Git tools.</description>
    </item>
    
    <item>
      <title>Create a Simple AWS CodePipeline from S3</title>
      <link>https://omar2cloud.github.io/aws/codepipeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://omar2cloud.github.io/aws/codepipeline/</guid>
      <description>AWS CodePipeline AWS CodePipeline is a continuous delivery service offered by AWS to model, visualize, and automate the release of applications. This service allows for rapid modeling and configuring of different steps of an application release process. It automates the necessary process of change of application deployment. For information about AWS CodePipeline.
Learning Outcomes and Tutorial Scenario: In this tutorial, we will create a two-stage pipeline that uses a versioned S3 bucket and CodeDeploy to release a sample application.</description>
    </item>
    
    <item>
      <title>Create a Terraform Template to Spin EC2 Instance from a RaspberryPi 4</title>
      <link>https://omar2cloud.github.io/aws/terraform/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://omar2cloud.github.io/aws/terraform/</guid>
      <description>What is Terraform? Terraform is an Infrastructure as a Code - IaaC- service. It is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions. For more information about Terraform.
During this tutorial, we will create a sample Terraform template to spin an AWS EC2 instance from the Command Line Interface (CLI) on a Raspberry Pi 4.</description>
    </item>
    
    <item>
      <title>Create a Static Sample Website on S3 Utilizing AWS CloudFormation</title>
      <link>https://omar2cloud.github.io/aws/s3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://omar2cloud.github.io/aws/s3/</guid>
      <description>AWS S3 Hosted Website: The objective of tutorial is to host a sample static website on AWS S3, obtain a free domain name from Freenom and assign it to the S3 website and utilize AWS Route 53 as DNS hosting provider. Moreover, an AWS CloudFront distribution is employed to serve the website over AWS&amp;rsquo;s fast content network service with low latency and Lambda@Edge is to add security headers to all web server responses.</description>
    </item>
    
    <item>
      <title>Autoscaling GitLab Runner on AWS Fargate</title>
      <link>https://omar2cloud.github.io/aws/_gitlab_fargate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://omar2cloud.github.io/aws/_gitlab_fargate/</guid>
      <description>What is GitLab Runner GitLab Runner is an application that works with GitLab CI/CD Continues Integration/Continuous Deployment method. Once GitLab Runner is installed and registered, it can run jobs in a pipeline. It&amp;rsquo;s an open source and written in Go language.
For more information about GitLab Runner, refer to GitLab&amp;rsquo;s official documentations.
What is AWS Fargate AWS Fargate is a serverless technology that you can use with Amazon ECS to run containers without managing servers or clusters of AWS EC2 instances.</description>
    </item>
    
  </channel>
</rss>
